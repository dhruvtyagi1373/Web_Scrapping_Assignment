{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14ce9ef-f1cf-43f3-8a0d-fb101e652955",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5908d4f6-0434-49dd-bb74-265212e2e147",
   "metadata": {},
   "source": [
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "1. Price Monitoring:\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research:\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring:\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!\n",
    "\n",
    "4. Sentiment Analysis:\n",
    "If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64a0ba-f81b-4504-9898-d67689ee9189",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3906d090-3f9e-4c01-aba6-13f5c55884a1",
   "metadata": {},
   "source": [
    "The most common techniques used for Web Scraping are:\n",
    "\n",
    "Human copy-and-paste.\n",
    "Text pattern matching.\n",
    "HTTP programming.\n",
    "HTML parsing.\n",
    "DOM parsing.\n",
    "Vertical aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99836c9a-a63e-49ba-a6b5-f2d9426c9545",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "108c3a57-f1b6-44f1-9fae-2a1c054295f0",
   "metadata": {},
   "source": [
    "Beautiful Soup is a python package and as the name suggests, parses the unwanted data and helps to organize and format the messy web data by fixing bad HTML and present to us in an easily-traversible XML structures.It is used so that the data can be in much more structured format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50e14d-d159-46e8-8359-fe30c9fa21e0",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c9a6845-4cdb-49f3-9f50-45b0b0e95fab",
   "metadata": {},
   "source": [
    "Flask is used in this web scrapping project so that the url can be created through flask by which a user can enter the details of the thing of which the user wants to scrape the data and get the required information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613a5c2-1067-4909-8638-ed65b4b9db3d",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "raw",
   "id": "01316f6a-5f0d-43c6-99ec-6c7204ba00cb",
   "metadata": {},
   "source": [
    "1. Code pipeline\n",
    "2. Elastic Beanstalk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "747dd83c-74a7-45b8-a045-bbc353339427",
   "metadata": {},
   "source": [
    "1. Code pipeline:\n",
    "AWS CodePipeline is an Amazon Web Services product that automates the software deployment process, allowing a developer to quickly model, visualize and deliver code for new features and updates. This method is called continuous delivery.\n",
    "AWS CodePipeline automatically builds, tests and launches an application each time the code is changed; a developer uses a graphic user interface to model workflow configurations for the release process within the pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8498e18f-572f-4698-9a4b-6f91cff369f1",
   "metadata": {},
   "source": [
    "2. Elastic Beanstalk:\n",
    "Elastic beanstalk is a pre-configured EC2 server that can directly take up your application code and environment configurations and use it to automatically provision and deploy the required resources within AWS to run the web application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
